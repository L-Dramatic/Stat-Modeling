import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import sys
import os

# å°è¯•å¯¼å…¥ç¾åŒ–èœå•åº“ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™é™çº§å¤„ç†
try:
    from streamlit_option_menu import option_menu
    HAS_OPTION_MENU = True
except ImportError:
    HAS_OPTION_MENU = False

# è®¾ç½®matplotlibå’Œseabornçš„å…¨å±€æ ·å¼
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# æ·»åŠ Codeç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥ä½ çš„æ¨¡å—
try:
    from data_preprocessing import DataPreprocessor
    from statistical_inference import StatisticalInference
    from glm_model import GLMModel
    from arima_model import ARIMAModel
    from hmm_model import HMMModel
except ImportError:
    pass

# ==========================================
# 1. é¡µé¢é…ç½®ä¸ CSS ç¾åŒ–
# ==========================================
st.set_page_config(
    page_title="ç©ºæ°”è´¨é‡ç›‘æµ‹é¢„è­¦ç³»ç»Ÿ",
    page_icon="ğŸŒ«ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ³¨å…¥è‡ªå®šä¹‰ CSS (è¿™æ˜¯å˜å¥½çœ‹çš„å…³é”®)
st.markdown("""
<style>
    /* å…¨å±€å­—ä½“ä¸èƒŒæ™¯ */
    @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Roboto', sans-serif;
    }
    
    /* ä¸»èƒŒæ™¯è‰²å¾®è°ƒ */
    .stApp {
        background-color: #f8f9fa;
    }
    
    /* æ ‡é¢˜æ ·å¼å¢å¼º */
    h1 {
        color: #2c3e50;
        font-weight: 700 !important;
        letter-spacing: -1px;
    }
    h2, h3 {
        color: #34495e;
        font-weight: 600 !important;
    }
    
    /* å¡ç‰‡å¼å®¹å™¨æ ·å¼ */
    .css-card {
        background-color: #ffffff;
        border-radius: 15px;
        padding: 20px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        margin-bottom: 20px;
        border: 1px solid #e9ecef;
    }
    
    /* æŒ‡æ ‡ (Metric) æ ·å¼ä¼˜åŒ– */
    div[data-testid="stMetric"] {
        background-color: white;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        border: 1px solid #eee;
        text-align: center;
    }
    div[data-testid="stMetricLabel"] {
        font-size: 0.9rem;
        color: #7f8c8d;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.8rem;
        color: #2980b9;
    }

    /* ä¾§è¾¹æ ä¼˜åŒ– */
    section[data-testid="stSidebar"] {
        background-color: #ffffff;
        border-right: 1px solid #eee;
    }
    
    /* æŒ‰é’®ç¾åŒ– */
    .stButton > button {
        background-color: #3498db;
        color: white;
        border-radius: 8px;
        border: none;
        padding: 0.5rem 1rem;
        transition: all 0.3s;
        width: 100%;
    }
    .stButton > button:hover {
        background-color: #2980b9;
        box-shadow: 0 4px 8px rgba(52, 152, 219, 0.3);
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘å‡½æ•° (é€»è¾‘ä¿æŒä¸å˜)
# ==========================================

def get_hmm_features(df):
    # ä½ è¿™ä»½ UCI æ•°æ®çš„å…¸å‹æ°”è±¡åˆ—
    candidate = ["DEWP", "TEMP", "PRES", "Iws", "Is", "Ir"]
    feats = [c for c in candidate if c in df.columns]
    return feats


def normalize_column_names(df):
    df = df.copy()
    column_mapping = {}
    pm25_variants = ['PM2.5','pm2.5','PM2_5','pm2_5','PM25','pm25','PM 2.5','pm 2.5']

    pm25_col = None
    for col in df.columns:
        if col in pm25_variants or col.strip() in pm25_variants:
            pm25_col = col
            break
    if pm25_col and pm25_col != 'PM2.5':
        df.rename(columns={pm25_col: 'PM2.5'}, inplace=True)

    date_variants = ['date','Date','DATE','datetime','DateTime','DATETIME','time','Time','timestamp','utc_time']
    date_col = None
    for col in df.columns:
        if col in date_variants:
            date_col = col
            break
    if date_col and date_col != 'date':
        df.rename(columns={date_col: 'date'}, inplace=True)

    return df, column_mapping


@st.cache_data
def load_data(file_path):
    """åŠ è½½æ•°æ® (ç¼“å­˜)"""
    try:
        if isinstance(file_path, str):
            df = pd.read_csv(file_path, na_values=['NA', 'NaN', '?', 'null'])
        else:
            df = pd.read_csv(file_path, na_values=['NA', 'NaN', '?', 'null'])
        
        df, mapping = normalize_column_names(df)
        lower_map = {c.lower(): c for c in df.columns}
        
        if 'date' not in df.columns:
            required_cols = ['year', 'month', 'day']
            if all(key in lower_map for key in required_cols):
                try:
                    datetime_parts = {
                        'year': df[lower_map['year']],
                        'month': df[lower_map['month']],
                        'day': df[lower_map['day']]
                    }
                    if 'hour' in lower_map:
                        datetime_parts['hour'] = df[lower_map['hour']]
                    
                    df['date'] = pd.to_datetime(datetime_parts, errors='coerce')
                    df = df.dropna(subset=['date']).set_index('date').sort_index()
                except:
                    pass
        else:
            try:
                df['date'] = pd.to_datetime(df['date'], errors='coerce')
                df = df.dropna(subset=['date']).set_index('date').sort_index()
            except:
                pass
        
        if 'PM2.5' not in df.columns:
            return None
        return df
    except Exception as e:
        print(f"Error: {e}")
        return None

@st.cache_data
def preprocess_data(df, missing_method="interpolation", outlier_method="3sigma", do_log=False):
    """æ•°æ®é¢„å¤„ç† (ç¼“å­˜) - è°ƒç”¨ DataPreprocessor"""
    if 'PM2.5' not in df.columns:
        return df

    pre = DataPreprocessor(df=df)

    # 1) ç¼ºå¤±å€¼
    pre.handle_missing_values(method=missing_method)

    # 2) å¼‚å¸¸å€¼
    if outlier_method != "none":
        pre.remove_outliers(column="PM2.5", method=outlier_method)

    df_processed = pre.get_processed_data()

    # 3) log å˜æ¢ï¼šä¸æ›¿æ¢åŸåˆ—ï¼Œåªå¢åŠ ä¸€åˆ—æ–¹ä¾¿å¯¹æ¯”
    if do_log:
        try:
            df_processed["log_PM2.5"] = pre.log_transform("PM2.5")
        except:
            pass

    return df_processed


# ==========================================
# 3. é¡µé¢è§†å›¾å‡½æ•° (UI å‡çº§ç‰ˆ)
# ==========================================

def page_data_insight(df):
    st.markdown("## ğŸ“Š æ•°æ®å…¨æ™¯æ´å¯Ÿ")
    
    # ä½¿ç”¨å®¹å™¨åŒ…è£¹ï¼Œå¢åŠ é—´è·
    with st.container():
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ğŸ“š æ€»è®°å½•æ•°", f"{len(df):,}")
        col2.metric("ğŸŒ«ï¸ PM2.5 å‡å€¼", f"{df['PM2.5'].mean():.1f}")
        col3.metric("ğŸ“ˆ PM2.5 å³°å€¼", f"{df['PM2.5'].max():.1f}")
        col4.metric("ğŸ“‰ å½“å‰ç¼ºå¤±å€¼", df['PM2.5'].isna().sum())
    
    st.markdown("---")

    # å›¾è¡¨åŒºåŸŸ 1
    col_chart1, col_chart2 = st.columns([2, 1])
    
    with col_chart1:
        st.markdown("### ğŸ“… å†å²è¶‹åŠ¿å›æº¯")
        if isinstance(df.index, pd.DatetimeIndex):
            fig = go.Figure()
            # é™é‡‡æ ·é˜²æ­¢å¡é¡¿
            plot_df = df.resample('D').mean(numeric_only=True) if len(df) > 10000 else df
            
            fig.add_trace(go.Scatter(
                x=plot_df.index, y=plot_df['PM2.5'],
                mode='lines', name='PM2.5',
                line=dict(color='#3498db', width=2),
                fill='tozeroy', fillcolor='rgba(52, 152, 219, 0.1)' 
            ))
            fig.update_layout(
                margin=dict(l=20, r=20, t=40, b=20),
                height=400, template='plotly_white',
                xaxis_title="", yaxis_title="PM2.5 æµ“åº¦ (Î¼g/mÂ³)"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("âš ï¸ æ•°æ®æœªåŒ…å«æ—¶é—´ç´¢å¼•ï¼Œæ— æ³•ç»˜åˆ¶è¶‹åŠ¿å›¾")

    with col_chart2:
        st.markdown("### ğŸŒ¡ï¸ ç›¸å…³æ€§çƒ­åŠ›å›¾")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        cols = [c for c in numeric_cols if c not in ['No', 'year', 'month', 'day', 'hour', 'is_weekend']]
        if len(cols) > 1:
            corr = df[cols].corr()
            fig, ax = plt.subplots(figsize=(5, 6))
            sns.heatmap(corr[['PM2.5']].sort_values(by='PM2.5', ascending=False), 
                        annot=True, fmt='.2f', cmap='coolwarm', cbar=False, ax=ax)
            ax.set_ylabel('')
            st.pyplot(fig)

    st.markdown("---")
    
    # æ›´å¤šåˆ†ææŠ˜å èµ·æ¥
    with st.expander("ğŸ§ æŸ¥çœ‹æ›´å¤šç»Ÿè®¡æ£€éªŒ (å·¥ä½œæ—¥æ•ˆåº” & å‘¨æœŸæ€§)"):
        if isinstance(df.index, pd.DatetimeIndex):
            df_wk = df.copy()
            
            # === [ä¿®å¤ç‚¹åœ¨è¿™é‡Œ] ===
            # åŸä»£ç æŠ¥é”™ï¼šAttributeError: 'numpy.ndarray' object has no attribute 'map'
            # ä¿®å¤æ–¹æ¡ˆï¼šä½¿ç”¨ np.whereï¼Œå¦‚æœ>=5åˆ™æ˜¯å‘¨æœ«ï¼Œå¦åˆ™æ˜¯å·¥ä½œæ—¥
            df_wk['Type'] = np.where(df_wk.index.dayofweek >= 5, 'å‘¨æœ«', 'å·¥ä½œæ—¥')
            # =====================
            
            col_ex1, col_ex2 = st.columns(2)
            with col_ex1:
                st.markdown("**å·¥ä½œæ—¥ vs å‘¨æœ«åˆ†å¸ƒ**")
                fig, ax = plt.subplots(figsize=(6, 4))
                # æŒ‡å®š order ç¡®ä¿é¡ºåºä¸€è‡´
                sns.boxplot(data=df_wk, x='Type', y='PM2.5', palette="Set2", ax=ax, order=['å·¥ä½œæ—¥', 'å‘¨æœ«'])
                st.pyplot(fig)
            with col_ex2:
                st.markdown("**ç»Ÿè®¡æ˜¾è‘—æ€§ (T-Test)**")
                try:
                    inference = StatisticalInference(df_wk)
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ å…¥ 0/1 çš„æ•°å€¼åˆ—ç»™ t_test è®¡ç®—ï¼Œå› ä¸º StatisticalInference å¯èƒ½ä¸æ”¯æŒä¸­æ–‡æ ‡ç­¾åˆ—è®¡ç®—
                    # æ‰€ä»¥æˆ‘ä»¬ä¸´æ—¶åŠ ä¸€ä¸ªæ•°å€¼æ ‡è¯†
                    df_wk['is_weekend_num'] = (df_wk.index.dayofweek >= 5).astype(int)
                    
                    res = inference.t_test('PM2.5', 'is_weekend_num') 
                    st.info(f"P-Value: **{res.get('p_value', 0):.4f}**")
                    if res.get('significant'):
                        st.success("âœ… å·®å¼‚æ˜¾è‘—ï¼šäººç±»æ´»åŠ¨å¯¹ç©ºæ°”è´¨é‡æœ‰æ˜æ˜¾å½±å“")
                    else:
                        st.warning("âš ï¸ å·®å¼‚ä¸æ˜¾è‘—")
                except Exception as e:
                    st.write(f"è®¡ç®—ç»Ÿè®¡é‡æ—¶å‡ºé”™: {e}")

def compute_vif(X_df):
    import statsmodels.api as sm
    from statsmodels.stats.outliers_influence import variance_inflation_factor

    X = sm.add_constant(X_df).dropna()
    vifs = []
    for i in range(X.shape[1]):
        vifs.append(variance_inflation_factor(X.values, i))
    return pd.DataFrame({"feature": X.columns, "VIF": vifs}).sort_values("VIF", ascending=False)


def page_attribution_analysis(df):
    st.markdown("## ğŸ” å½’å› åˆ†æå®éªŒå®¤")
    st.info("ğŸ’¡ é€šè¿‡ç»Ÿè®¡æ¨¡å‹é‡åŒ–å„ä¸ªæ°”è±¡å› å­å¯¹ PM2.5 çš„å…·ä½“è´¡çŒ®åº¦ã€‚")
    
    col_ctrl, col_res = st.columns([1, 3])
    
    with col_ctrl:
        st.markdown("#### âš™ï¸ å‚æ•°é…ç½®")
        with st.form("model_params"):
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            features = [c for c in numeric_cols if c not in ['PM2.5', 'No', 'year', 'month', 'day', 'hour']]
            
            selected_features = st.multiselect("é€‰æ‹©ç‰¹å¾å˜é‡", features, default=features[:4] if features else [])
            model_type = st.radio("æ¨¡å‹é€‰æ‹©", ["OLS (çº¿æ€§å›å½’)", "GLM (Gammaåˆ†å¸ƒ)"])
            
            submit = st.form_submit_button("ğŸš€ å¼€å§‹å»ºæ¨¡")
    
    with col_res:
        if submit and selected_features:
            with st.spinner("æ­£åœ¨æ‹Ÿåˆæ¨¡å‹..."):
                try:
                    import statsmodels.api as sm
                    X_raw = df[selected_features]
                    X = sm.add_constant(X_raw).dropna()
                    y = df.loc[X.index, 'PM2.5']

                    if "OLS" in model_type:
                        model = sm.OLS(y, X).fit()
                        title = "OLS çº¿æ€§å›å½’ç»“æœ"
                        coefs = model.params.drop('const', errors='ignore')
                        pvals = model.pvalues.drop('const', errors='ignore')

                        st.markdown(f"#### ğŸ“Š {title}")

                        fig, ax = plt.subplots(figsize=(10, 4))
                        colors = ['#2ecc71' if p < 0.05 else '#95a5a6' for p in pvals]
                        coefs.plot(kind='bar', color=colors, ax=ax)
                        ax.set_title("Feature Coefficients (green = significant)", fontsize=10)
                        ax.axhline(0, color='black', linewidth=0.8)
                        st.pyplot(fig)

                        with st.expander("ğŸ“„ æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡æŠ¥è¡¨"):
                            st.text(model.summary())

                    else:
                        # âœ… ç”¨ä½ çš„ GLMModel
                        glm = GLMModel()
                        glm.fit(X_raw.dropna(), y.loc[X_raw.dropna().index])
                        title = "GLM (Gamma + log link) ç»“æœ"

                        st.markdown(f"#### ğŸ“Š {title}")

                        sig = glm.get_significant_features(alpha=0.05)
                        coefs = glm.results.params.drop('const', errors='ignore')
                        pvals = glm.results.pvalues.drop('const', errors='ignore')

                        fig, ax = plt.subplots(figsize=(10, 4))
                        colors = ['#2ecc71' if p < 0.05 else '#95a5a6' for p in pvals]
                        coefs.plot(kind='bar', color=colors, ax=ax)
                        ax.set_title("GLM Coefficients (Gamma + log link)", fontsize=10)
                        ax.axhline(0, color='black', linewidth=0.8)
                        st.pyplot(fig)

                        with st.expander("ğŸ“Œ æ˜¾è‘—å› å­è§£é‡Šï¼ˆç›¸å¯¹å˜åŒ–%ï¼‰", expanded=True):
                            if sig.empty:
                                st.warning("æ²¡æœ‰æ˜¾è‘—å› å­ï¼ˆp<0.05ï¼‰")
                            else:
                                for feat in sig.index:
                                    st.write(glm.interpret_coefficient(feat))

                        with st.expander("ğŸ“„ æŸ¥çœ‹ GLM ç»Ÿè®¡æŠ¥è¡¨"):
                            st.text(glm.get_summary())

                    # âœ… VIF å…±çº¿æ€§
                    with st.expander("ğŸ§ª å¤šé‡å…±çº¿æ€§è¯Šæ–­ï¼ˆVIFï¼‰", expanded=False):
                        vif_df = compute_vif(df[selected_features])
                        st.dataframe(vif_df, use_container_width=True)
                        high_vif = vif_df[vif_df["VIF"] > 10]
                        if len(high_vif) > 0:
                            st.warning("ä»¥ä¸‹å˜é‡ VIF>10ï¼Œå…±çº¿æ€§è¾ƒå¼ºï¼Œå»ºè®®åˆ å‡æˆ–åˆå¹¶ï¼š")
                            st.write(high_vif)

                        
                except Exception as e:
                    st.error(f"å»ºæ¨¡å¤±è´¥: {str(e)}")
        elif not submit:
            st.markdown("""
            <div style="text-align: center; padding: 50px; color: #95a5a6;">
                ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©ç‰¹å¾å¹¶ç‚¹å‡»è¿è¡Œ
            </div>
            """, unsafe_allow_html=True)

def page_warning_center(df):
    st.markdown("## âš ï¸ æ™ºèƒ½é¢„è­¦ä¸­å¿ƒ")

    if not isinstance(df.index, pd.DatetimeIndex):
        st.error("å½“å‰æ•°æ®æ²¡æœ‰æ—¶é—´ç´¢å¼•ï¼Œæ— æ³•è¿›è¡Œ HMM/ARIMA é¢„è­¦ã€‚")
        return

    # =======================
    # 1) HMM çŠ¶æ€è¯†åˆ«
    # =======================
    st.markdown("### ğŸ² çŠ¶æ€è¯†åˆ« (HMM)")
    feats = get_hmm_features(df)

    if len(feats) == 0:
        st.warning("æœªæ‰¾åˆ°æ°”è±¡ç‰¹å¾åˆ—ï¼ˆDEWP/TEMP/PRES/Iws/Is/Irï¼‰ï¼Œæ— æ³•æ‹Ÿåˆ HMMã€‚")
    else:
        col1, col2 = st.columns([1, 2])

        with col1:
            n_states = st.slider("éšçŠ¶æ€æ•°é‡", 2, 5, 3)
            hmm_mode = st.radio("çŠ¶æ€å®šä¹‰æ–¹å¼", ["é˜ˆå€¼ï¼ˆå›½æ ‡ï¼‰", "åˆ†ä½æ•°"], index=0)

            run_hmm = st.button("ğŸš€ æ‹Ÿåˆ HMM å¹¶æ¨æ–­å½“å‰çŠ¶æ€", use_container_width=True)

        with col2:
            st.markdown("**HMM è§‚æµ‹ç‰¹å¾ï¼š** " + ", ".join(feats))

        if run_hmm:
            with st.spinner("HMM è®­ç»ƒä¸­..."):
                obs = df[feats].dropna()
                pm25 = df.loc[obs.index, "PM2.5"].dropna()
                obs = obs.loc[pm25.index]

                hmm_model = HMMModel(n_states=n_states)

                # ç”¨ PM2.5 æ¥å®šä¹‰ state çš„é˜ˆå€¼/åˆ†ä½æ•°ï¼ˆåœ¨æ¨¡å‹é‡Œï¼‰
                hmm_model.fit(obs.values, pm25_values=pm25.values)

                # æ¨æ–­å…¨åºåˆ—çŠ¶æ€
                states = hmm_model.predict_states(obs.values)

                # âœ… å¯¹é½çŠ¶æ€å«ä¹‰ï¼šæŒ‰æ¯ä¸ª state çš„ PM2.5 å‡å€¼æ’åº
                state_means = {}
                for s in range(n_states):
                    state_means[s] = pm25.values[states == s].mean()

                sorted_states = sorted(state_means, key=state_means.get)
                mapped_names = []
                if n_states == 3 and hmm_mode.startswith("é˜ˆå€¼"):
                    mapped_names = ["ä¼˜è‰¯", "è½»åº¦æ±¡æŸ“", "é‡åº¦æ±¡æŸ“"]
                else:
                    mapped_names = [f"çŠ¶æ€{i+1}" for i in range(n_states)]

                mapping = {s: mapped_names[i] for i, s in enumerate(sorted_states)}
                current_state = mapping[states[-1]]

                st.success(f"å½“å‰éšçŠ¶æ€ï¼š**{current_state}**")
                mean_df = pd.DataFrame({
                    "state": list(state_means.keys()),
                    "PM2.5_mean": list(state_means.values())
                }).sort_values("PM2.5_mean")
                st.markdown("**å„çŠ¶æ€ PM2.5 å‡å€¼ï¼ˆç”¨äºè§£é‡Šå¯¹é½ï¼‰ï¼š**")
                st.dataframe(mean_df, use_container_width=True)

                st.markdown("#### ğŸ” çŠ¶æ€è½¬ç§»çŸ©é˜µ")
                trans = hmm_model.get_transition_matrix().copy()
                # é‡æ–°æŒ‰ mapping æ’åº/é‡å‘½å
                trans.index = [mapping.get(i, i) for i in trans.index]
                trans.columns = [mapping.get(i, i) for i in trans.columns]
                st.dataframe(trans, use_container_width=True)

                st.markdown("#### ğŸ“Œ æœ€è¿‘ 7 å¤©éšçŠ¶æ€åºåˆ—")
                last_idx = obs.index[-24*7:] if len(obs) >= 24*7 else obs.index
                last_states = states[-len(last_idx):]
                state_series = pd.Series([mapping[s] for s in last_states], index=last_idx)

                fig = go.Figure()
                fig.add_trace(go.Scatter(x=state_series.index, y=state_series.values, mode="lines"))
                fig.update_layout(height=250, margin=dict(t=20,b=0,l=0,r=0))
                st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    # =======================
    # 2) ARIMA çŸ­æœŸé¢„æµ‹
    # =======================
    st.markdown("### ğŸ”® è¶‹åŠ¿é¢„æµ‹ (ARIMA)")

    steps = st.slider("é¢„æµ‹æœªæ¥å°æ—¶æ•°", 12, 72, 24)
    run_arima = st.button("ğŸ“ˆ ç”Ÿæˆ ARIMA é¢„æµ‹", type="primary", use_container_width=True)

    if run_arima:
        with st.spinner("ARIMA æ‹Ÿåˆä¸é¢„æµ‹ä¸­..."):
            series = df["PM2.5"].dropna()

            arima = ARIMAModel()

            # å¹³ç¨³æ€§æ£€éªŒ
            stat_res = arima.check_stationarity(series)
            st.write("ADF æ£€éªŒç»“æœï¼š", stat_res)

            # æ‹Ÿåˆï¼ˆè‡ªåŠ¨é€‰å‚ï¼‰
            arima.fit(series, auto_select=True)

            # é¢„æµ‹
            forecast_df = arima.predict(steps=steps, alpha=0.05)

            st.markdown("#### ğŸ“Š é¢„æµ‹æ›²çº¿ï¼ˆå«95%ç½®ä¿¡åŒºé—´ï¼‰")
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=series.index, y=series.values, mode="lines", name="å†å² PM2.5"
            ))
            fig.add_trace(go.Scatter(
                x=forecast_df.index, y=forecast_df["forecast"],
                mode="lines+markers", name="é¢„æµ‹"
            ))
            fig.add_trace(go.Scatter(
                x=forecast_df.index, y=forecast_df["upper"],
                mode="lines", name="ä¸Šç•Œ", line=dict(width=0),
                showlegend=False
            ))
            fig.add_trace(go.Scatter(
                x=forecast_df.index, y=forecast_df["lower"],
                mode="lines", name="ä¸‹ç•Œ", fill="tonexty",
                line=dict(width=0), showlegend=False
            ))
            fig.update_layout(height=350, margin=dict(t=20,b=0,l=0,r=0))
            st.plotly_chart(fig, use_container_width=True)

            with st.expander("ğŸ“„ ARIMA æ¨¡å‹æ‘˜è¦"):
                st.text(arima.get_summary())


# ==========================================
# 4. ä¸»ç¨‹åºå…¥å£
# ==========================================

def main():
    # è·¯å¾„è®¾ç½®
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    default_data_path = os.path.normpath(os.path.join(current_script_dir, '..', 'Data', 'PRSA_data_2010.1.1-2014.12.31.csv'))

    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3208/3208728.png", width=60)
        st.markdown("### ç©ºæ°”è´¨é‡ç›‘æµ‹ç³»ç»Ÿ")
        st.markdown("Version 2.0 | Pro Edition")
        
        st.markdown("---")
        
        # æ¼‚äº®çš„èœå•ç»„ä»¶
        if HAS_OPTION_MENU:
            selected = option_menu(
                menu_title=None,
                options=["æ•°æ®æ´å¯Ÿ", "å½’å› åˆ†æ", "é¢„è­¦ä¸­å¿ƒ"],
                icons=["bar-chart-fill", "search", "shield-exclamation"],
                menu_icon="cast",
                default_index=0,
                styles={
                    "container": {"padding": "0!important", "background-color": "#fafafa"},
                    "icon": {"color": "#2980b9", "font-size": "16px"}, 
                    "nav-link": {"font-size": "14px", "text-align": "left", "margin":"0px", "--hover-color": "#eee"},
                    "nav-link-selected": {"background-color": "#3498db"},
                }
            )
        else:
            selected = st.radio("å¯¼èˆª", ["æ•°æ®æ´å¯Ÿ", "å½’å› åˆ†æ", "é¢„è­¦ä¸­å¿ƒ"])
        
        st.markdown("---")
        
        # æ•°æ®åŠ è½½åŒº
        with st.expander("ğŸ“‚ æ•°æ®ç®¡ç†", expanded=True):
            uploaded_file = st.file_uploader("ä¸Šä¼  CSV", type=['csv'])
            st.markdown("### ğŸ§¹ é¢„å¤„ç†è®¾ç½®")
            missing_method = st.selectbox("ç¼ºå¤±å€¼å¤„ç†", ["interpolation", "drop"], index=0)
            outlier_method = st.selectbox("å¼‚å¸¸å€¼å¤„ç†", ["3sigma", "iqr", "none"], index=0)
            do_log = st.checkbox("å¯¹ PM2.5 åš Log å˜æ¢ï¼ˆç”¨äºæ£€éªŒ/å»ºæ¨¡å¯¹æ¯”ï¼‰", value=False)    
            if st.button("ğŸ”„ åŠ è½½æµ‹è¯•æ•°æ®"):
                if os.path.exists(default_data_path):
                    st.session_state['data'] = load_data(default_data_path)
                    if 'processed_data' in st.session_state: del st.session_state['processed_data']
                    st.rerun()
                else:
                    st.error("æµ‹è¯•æ–‡ä»¶æœªæ‰¾åˆ°")              
        if 'data' in st.session_state:
            st.success(f"å·²åŠ è½½ {len(st.session_state['data'])} æ¡æ•°æ®")

    # ä¸»é€»è¾‘è·¯ç”±
    if 'data' in st.session_state:
        df = st.session_state['data'].copy()
        
        if 'processed_data' not in st.session_state:
            with st.spinner("æ­£åœ¨è¿›è¡Œæ™ºèƒ½æ¸…æ´—ä¸é¢„å¤„ç†..."):
                df_processed = preprocess_data(
                    df,
                    missing_method=missing_method,
                    outlier_method=outlier_method,
                    do_log=do_log
                )

                st.session_state['processed_data'] = df_processed
        else:
            df_processed = st.session_state['processed_data']
        
        # é¡µé¢è·³è½¬
        if selected == "æ•°æ®æ´å¯Ÿ":
            page_data_insight(df_processed)
        elif selected == "å½’å› åˆ†æ":
            page_attribution_analysis(df_processed)
        elif selected == "é¢„è­¦ä¸­å¿ƒ":
            page_warning_center(df_processed)
            
    else:
        # æ¬¢è¿é¡µï¼ˆç©ºçŠ¶æ€ï¼‰
        st.markdown("""
        <div style="display: flex; justify-content: center; align-items: center; height: 60vh; flex-direction: column;">
            <h2 style="color: #ccc;">ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ç³»ç»Ÿ</h2>
            <p style="color: #999;">è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ åŠ è½½æ•°æ®ä»¥å¼€å§‹åˆ†æ</p>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()