import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import statsmodels.api as sm
import sys
import os

# å°è¯•å¯¼å…¥ç¾åŒ–èœå•åº“ï¼Œå¦‚æœæ²¡æœ‰å®‰è£…åˆ™é™çº§å¤„ç†
try:
    from streamlit_option_menu import option_menu
    HAS_OPTION_MENU = True
except ImportError:
    HAS_OPTION_MENU = False

# è®¾ç½®matplotlibå’Œseabornçš„å…¨å±€æ ·å¼
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# è®¾ç½®matplotlibä¸­æ–‡å­—ä½“æ”¯æŒï¼ˆè§£å†³ä¸­æ–‡ä¹±ç é—®é¢˜ï¼‰
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# æ·»åŠ Codeç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥ä½ çš„æ¨¡å—
try:
    from data_preprocessing import DataPreprocessor
    from statistical_inference import StatisticalInference
    from glm_model import GLMModel
    from arima_model import ARIMAModel
    from hmm_model import HMMModel
    # æ–°å¢æ¨¡å—
    from classification_models import ClassificationModels
    from model_evaluation import ModelEvaluator
    from bayesian_models import BayesianModels
    from regression_models import RegressionModels
    from feature_selection import FeatureSelector
except ImportError as e:
    st.warning(f"éƒ¨åˆ†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    pass

# ==========================================
# 1. é¡µé¢é…ç½®ä¸ CSS ç¾åŒ–
# ==========================================
st.set_page_config(
    page_title="ç©ºæ°”è´¨é‡ç›‘æµ‹é¢„è­¦ç³»ç»Ÿ",
    page_icon="ğŸŒ«ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ³¨å…¥è‡ªå®šä¹‰ CSS (è¿™æ˜¯å˜å¥½çœ‹çš„å…³é”®)
st.markdown("""
<style>
    /* å…¨å±€å­—ä½“ä¸èƒŒæ™¯ */
    @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap');
    
    html, body, [class*="css"] {
        font-family: 'Roboto', sans-serif;
    }
    
    /* ä¸»èƒŒæ™¯è‰²å¾®è°ƒ */
    .stApp {
        background-color: #f8f9fa;
    }
    
    /* æ ‡é¢˜æ ·å¼å¢å¼º */
    h1 {
        color: #2c3e50;
        font-weight: 700 !important;
        letter-spacing: -1px;
    }
    h2, h3 {
        color: #34495e;
        font-weight: 600 !important;
    }
    
    /* å¡ç‰‡å¼å®¹å™¨æ ·å¼ */
    .css-card {
        background-color: #ffffff;
        border-radius: 15px;
        padding: 20px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
        margin-bottom: 20px;
        border: 1px solid #e9ecef;
    }
    
    /* æŒ‡æ ‡ (Metric) æ ·å¼ä¼˜åŒ– */
    div[data-testid="stMetric"] {
        background-color: white;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        border: 1px solid #eee;
        text-align: center;
    }
    div[data-testid="stMetricLabel"] {
        font-size: 0.9rem;
        color: #7f8c8d;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.8rem;
        color: #2980b9;
    }

    /* ä¾§è¾¹æ ä¼˜åŒ– */
    section[data-testid="stSidebar"] {
        background-color: #ffffff;
        border-right: 1px solid #eee;
    }
    
    /* æŒ‰é’®ç¾åŒ– */
    .stButton > button {
        background-color: #3498db;
        color: white;
        border-radius: 8px;
        border: none;
        padding: 0.5rem 1rem;
        transition: all 0.3s;
        width: 100%;
    }
    .stButton > button:hover {
        background-color: #2980b9;
        box-shadow: 0 4px 8px rgba(52, 152, 219, 0.3);
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘å‡½æ•° (é€»è¾‘ä¿æŒä¸å˜)
# ==========================================

def get_hmm_features(df):
    # ä½ è¿™ä»½ UCI æ•°æ®çš„å…¸å‹æ°”è±¡åˆ—
    candidate = ["DEWP", "TEMP", "PRES", "Iws", "Is", "Ir"]
    feats = [c for c in candidate if c in df.columns]
    return feats


def normalize_column_names(df):
    df = df.copy()
    column_mapping = {}
    pm25_variants = ['PM2.5','pm2.5','PM2_5','pm2_5','PM25','pm25','PM 2.5','pm 2.5']

    pm25_col = None
    for col in df.columns:
        if col in pm25_variants or col.strip() in pm25_variants:
            pm25_col = col
            break
    if pm25_col and pm25_col != 'PM2.5':
        df.rename(columns={pm25_col: 'PM2.5'}, inplace=True)

    date_variants = ['date','Date','DATE','datetime','DateTime','DATETIME','time','Time','timestamp','utc_time']
    date_col = None
    for col in df.columns:
        if col in date_variants:
            date_col = col
            break
    if date_col and date_col != 'date':
        df.rename(columns={date_col: 'date'}, inplace=True)

    return df, column_mapping


@st.cache_data
def load_data(file_path):
    """åŠ è½½æ•°æ® (ç¼“å­˜)"""
    try:
        if isinstance(file_path, str):
            df = pd.read_csv(file_path, na_values=['NA', 'NaN', '?', 'null'])
        else:
            # å¦‚æœæ˜¯ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡ï¼Œéœ€è¦é‡ç½®æŒ‡é’ˆ
            if hasattr(file_path, 'seek'):
                file_path.seek(0)
            df = pd.read_csv(file_path, na_values=['NA', 'NaN', '?', 'null'])
        
        df, mapping = normalize_column_names(df)
        lower_map = {c.lower(): c for c in df.columns}
        
        if 'date' not in df.columns:
            required_cols = ['year', 'month', 'day']
            if all(key in lower_map for key in required_cols):
                try:
                    datetime_parts = {
                        'year': df[lower_map['year']],
                        'month': df[lower_map['month']],
                        'day': df[lower_map['day']]
                    }
                    if 'hour' in lower_map:
                        datetime_parts['hour'] = df[lower_map['hour']]
                    
                    df['date'] = pd.to_datetime(datetime_parts, errors='coerce')
                    df = df.dropna(subset=['date']).set_index('date').sort_index()
                except:
                    pass
        else:
            try:
                df['date'] = pd.to_datetime(df['date'], errors='coerce')
                df = df.dropna(subset=['date']).set_index('date').sort_index()
            except:
                pass
        
        if 'PM2.5' not in df.columns:
            return None
        return df
    except Exception as e:
        print(f"Error: {e}")
        return None

@st.cache_data
def preprocess_data(df, missing_method="interpolation", outlier_method="3sigma", do_log=False):
    """æ•°æ®é¢„å¤„ç† (ç¼“å­˜) - è°ƒç”¨ DataPreprocessor"""
    if 'PM2.5' not in df.columns:
        return df

    pre = DataPreprocessor(df=df)

    # 1) ç¼ºå¤±å€¼
    pre.handle_missing_values(method=missing_method)

    # 2) å¼‚å¸¸å€¼
    if outlier_method != "none":
        pre.remove_outliers(column="PM2.5", method=outlier_method)

    df_processed = pre.get_processed_data()

    # 3) log å˜æ¢ï¼šä¸æ›¿æ¢åŸåˆ—ï¼Œåªå¢åŠ ä¸€åˆ—æ–¹ä¾¿å¯¹æ¯”
    if do_log:
        try:
            df_processed["log_PM2.5"] = pre.log_transform("PM2.5")
        except:
            pass

    return df_processed


# ==========================================
# 3. é¡µé¢è§†å›¾å‡½æ•° (UI å‡çº§ç‰ˆ)
# ==========================================

def page_data_insight(df):
    st.markdown("## ğŸ“Š æ•°æ®å…¨æ™¯æ´å¯Ÿ")
    
    # ä½¿ç”¨å®¹å™¨åŒ…è£¹ï¼Œå¢åŠ é—´è·
    with st.container():
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ğŸ“š æ€»è®°å½•æ•°", f"{len(df):,}")
        col2.metric("ğŸŒ«ï¸ PM2.5 å‡å€¼", f"{df['PM2.5'].mean():.1f}")
        col3.metric("ğŸ“ˆ PM2.5 å³°å€¼", f"{df['PM2.5'].max():.1f}")
        col4.metric("ğŸ“‰ å½“å‰ç¼ºå¤±å€¼", df['PM2.5'].isna().sum())
    
    st.markdown("---")

    # å›¾è¡¨åŒºåŸŸ 1
    col_chart1, col_chart2 = st.columns([2, 1])
    
    with col_chart1:
        st.markdown("### ğŸ“… å†å²è¶‹åŠ¿å›æº¯")
        if isinstance(df.index, pd.DatetimeIndex):
            fig = go.Figure()
            # é™é‡‡æ ·é˜²æ­¢å¡é¡¿
            plot_df = df.resample('D').mean(numeric_only=True) if len(df) > 10000 else df
            
            fig.add_trace(go.Scatter(
                x=plot_df.index, y=plot_df['PM2.5'],
                mode='lines', name='PM2.5',
                line=dict(color='#3498db', width=2),
                fill='tozeroy', fillcolor='rgba(52, 152, 219, 0.1)' 
            ))
            fig.update_layout(
                margin=dict(l=20, r=20, t=40, b=20),
                height=400, template='plotly_white',
                xaxis_title="", yaxis_title="PM2.5 æµ“åº¦ (Î¼g/mÂ³)"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("âš ï¸ æ•°æ®æœªåŒ…å«æ—¶é—´ç´¢å¼•ï¼Œæ— æ³•ç»˜åˆ¶è¶‹åŠ¿å›¾")

    with col_chart2:
        st.markdown("### ğŸŒ¡ï¸ ç›¸å…³æ€§çƒ­åŠ›å›¾")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        cols = [c for c in numeric_cols if c not in ['No', 'year', 'month', 'day', 'hour', 'is_weekend']]
        if len(cols) > 1:
            corr = df[cols].corr()
            fig, ax = plt.subplots(figsize=(5, 6))
            sns.heatmap(corr[['PM2.5']].sort_values(by='PM2.5', ascending=False), 
                        annot=True, fmt='.2f', cmap='coolwarm', cbar=False, ax=ax)
            ax.set_ylabel('')
            st.pyplot(fig)

    st.markdown("---")
    
    # æ›´å¤šåˆ†ææŠ˜å èµ·æ¥
    with st.expander("ğŸ§ æŸ¥çœ‹æ›´å¤šç»Ÿè®¡æ£€éªŒ (å·¥ä½œæ—¥æ•ˆåº” & å‘¨æœŸæ€§)"):
        if isinstance(df.index, pd.DatetimeIndex):
            df_wk = df.copy()
            
            # === [ä¿®å¤ç‚¹åœ¨è¿™é‡Œ] ===
            # åŸä»£ç æŠ¥é”™ï¼šAttributeError: 'numpy.ndarray' object has no attribute 'map'
            # ä¿®å¤æ–¹æ¡ˆï¼šä½¿ç”¨ np.whereï¼Œå¦‚æœ>=5åˆ™æ˜¯å‘¨æœ«ï¼Œå¦åˆ™æ˜¯å·¥ä½œæ—¥
            df_wk['Type'] = np.where(df_wk.index.dayofweek >= 5, 'å‘¨æœ«', 'å·¥ä½œæ—¥')
            # =====================
            
            col_ex1, col_ex2 = st.columns(2)
            with col_ex1:
                st.markdown("**å·¥ä½œæ—¥ vs å‘¨æœ«åˆ†å¸ƒ**")
                fig, ax = plt.subplots(figsize=(6, 4))
                # æŒ‡å®š order ç¡®ä¿é¡ºåºä¸€è‡´
                sns.boxplot(data=df_wk, x='Type', y='PM2.5', palette="Set2", ax=ax, order=['å·¥ä½œæ—¥', 'å‘¨æœ«'])
                st.pyplot(fig)
            with col_ex2:
                st.markdown("**ç»Ÿè®¡æ˜¾è‘—æ€§ (T-Test)**")
                try:
                    inference = StatisticalInference(df_wk)
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¼ å…¥ 0/1 çš„æ•°å€¼åˆ—ç»™ t_test è®¡ç®—ï¼Œå› ä¸º StatisticalInference å¯èƒ½ä¸æ”¯æŒä¸­æ–‡æ ‡ç­¾åˆ—è®¡ç®—
                    # æ‰€ä»¥æˆ‘ä»¬ä¸´æ—¶åŠ ä¸€ä¸ªæ•°å€¼æ ‡è¯†
                    df_wk['is_weekend_num'] = (df_wk.index.dayofweek >= 5).astype(int)
                    
                    res = inference.t_test('PM2.5', 'is_weekend_num') 
                    st.info(f"P-Value: **{res.get('p_value', 0):.4f}**")
                    if res.get('significant'):
                        st.success("âœ… å·®å¼‚æ˜¾è‘—ï¼šäººç±»æ´»åŠ¨å¯¹ç©ºæ°”è´¨é‡æœ‰æ˜æ˜¾å½±å“")
                    else:
                        st.warning("âš ï¸ å·®å¼‚ä¸æ˜¾è‘—")
                except Exception as e:
                    st.write(f"è®¡ç®—ç»Ÿè®¡é‡æ—¶å‡ºé”™: {e}")

def compute_vif(X_df):
    import statsmodels.api as sm
    from statsmodels.stats.outliers_influence import variance_inflation_factor

    X = sm.add_constant(X_df).dropna()
    vifs = []
    for i in range(X.shape[1]):
        vifs.append(variance_inflation_factor(X.values, i))
    return pd.DataFrame({"feature": X.columns, "VIF": vifs}).sort_values("VIF", ascending=False)


def page_attribution_analysis(df):
    st.markdown("## ğŸ” å½’å› åˆ†æå®éªŒå®¤")
    st.info("ğŸ’¡ é€šè¿‡ç»Ÿè®¡æ¨¡å‹é‡åŒ–å„ä¸ªæ°”è±¡å› å­å¯¹ PM2.5 çš„å…·ä½“è´¡çŒ®åº¦ã€‚")
    
    col_ctrl, col_res = st.columns([1, 3])
    
    with col_ctrl:
        st.markdown("#### âš™ï¸ å‚æ•°é…ç½®")
        with st.form("model_params"):
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            features = [c for c in numeric_cols if c not in ['PM2.5', 'No', 'year', 'month', 'day', 'hour']]
            
            selected_features = st.multiselect("é€‰æ‹©ç‰¹å¾å˜é‡", features, default=features[:4] if features else [])
            model_type = st.radio("æ¨¡å‹é€‰æ‹©", ["OLS (çº¿æ€§å›å½’)", "GLM (Gammaåˆ†å¸ƒ)"])
            
            submit = st.form_submit_button("ğŸš€ å¼€å§‹å»ºæ¨¡")
    
    with col_res:
        if submit and selected_features:
            with st.spinner("æ­£åœ¨æ‹Ÿåˆæ¨¡å‹..."):
                try:
                    import statsmodels.api as sm
                    X_raw = df[selected_features]
                    X = sm.add_constant(X_raw).dropna()
                    y = df.loc[X.index, 'PM2.5']

                    if "OLS" in model_type:
                        model = sm.OLS(y, X).fit()
                        title = "OLS çº¿æ€§å›å½’ç»“æœ"
                        coefs = model.params.drop('const', errors='ignore')
                        pvals = model.pvalues.drop('const', errors='ignore')

                        st.markdown(f"#### ğŸ“Š {title}")

                        fig, ax = plt.subplots(figsize=(10, 4))
                        colors = ['#2ecc71' if p < 0.05 else '#95a5a6' for p in pvals]
                        coefs.plot(kind='bar', color=colors, ax=ax)
                        ax.set_title("Feature Coefficients (green = significant)", fontsize=10)
                        ax.axhline(0, color='black', linewidth=0.8)
                        st.pyplot(fig)

                        with st.expander("ğŸ“„ æŸ¥çœ‹è¯¦ç»†ç»Ÿè®¡æŠ¥è¡¨"):
                            st.text(model.summary())

                    else:
                        # âœ… ç”¨ä½ çš„ GLMModel
                        glm = GLMModel()
                        glm.fit(X_raw.dropna(), y.loc[X_raw.dropna().index])
                        title = "GLM (Gamma + log link) ç»“æœ"

                        st.markdown(f"#### ğŸ“Š {title}")

                        sig = glm.get_significant_features(alpha=0.05)
                        coefs = glm.results.params.drop('const', errors='ignore')
                        pvals = glm.results.pvalues.drop('const', errors='ignore')

                        fig, ax = plt.subplots(figsize=(10, 4))
                        colors = ['#2ecc71' if p < 0.05 else '#95a5a6' for p in pvals]
                        coefs.plot(kind='bar', color=colors, ax=ax)
                        ax.set_title("GLM Coefficients (Gamma + log link)", fontsize=10)
                        ax.axhline(0, color='black', linewidth=0.8)
                        st.pyplot(fig)

                        with st.expander("ğŸ“Œ æ˜¾è‘—å› å­è§£é‡Šï¼ˆç›¸å¯¹å˜åŒ–%ï¼‰", expanded=True):
                            if sig.empty:
                                st.warning("æ²¡æœ‰æ˜¾è‘—å› å­ï¼ˆp<0.05ï¼‰")
                            else:
                                for feat in sig.index:
                                    st.write(glm.interpret_coefficient(feat))

                        with st.expander("ğŸ“„ æŸ¥çœ‹ GLM ç»Ÿè®¡æŠ¥è¡¨"):
                            st.text(glm.get_summary())

                    # âœ… VIF å…±çº¿æ€§
                    with st.expander("ğŸ§ª å¤šé‡å…±çº¿æ€§è¯Šæ–­ï¼ˆVIFï¼‰", expanded=False):
                        vif_df = compute_vif(df[selected_features])
                        st.dataframe(vif_df, use_container_width=True)
                        high_vif = vif_df[vif_df["VIF"] > 10]
                        if len(high_vif) > 0:
                            st.warning("ä»¥ä¸‹å˜é‡ VIF>10ï¼Œå…±çº¿æ€§è¾ƒå¼ºï¼Œå»ºè®®åˆ å‡æˆ–åˆå¹¶ï¼š")
                            st.write(high_vif)

                        
                except Exception as e:
                    st.error(f"å»ºæ¨¡å¤±è´¥: {str(e)}")
        elif not submit:
            st.markdown("""
            <div style="text-align: center; padding: 50px; color: #95a5a6;">
                ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©ç‰¹å¾å¹¶ç‚¹å‡»è¿è¡Œ
            </div>
            """, unsafe_allow_html=True)

def page_warning_center(df):
    st.markdown("## âš ï¸ æ™ºèƒ½é¢„è­¦ä¸­å¿ƒ")

    if not isinstance(df.index, pd.DatetimeIndex):
        st.error("å½“å‰æ•°æ®æ²¡æœ‰æ—¶é—´ç´¢å¼•ï¼Œæ— æ³•è¿›è¡Œ HMM/ARIMA é¢„è­¦ã€‚")
        return

    # =======================
    # 1) HMM çŠ¶æ€è¯†åˆ«
    # =======================
    st.markdown("### ğŸ² çŠ¶æ€è¯†åˆ« (HMM)")
    feats = get_hmm_features(df)

    if len(feats) == 0:
        st.warning("æœªæ‰¾åˆ°æ°”è±¡ç‰¹å¾åˆ—ï¼ˆDEWP/TEMP/PRES/Iws/Is/Irï¼‰ï¼Œæ— æ³•æ‹Ÿåˆ HMMã€‚")
    else:
        col1, col2 = st.columns([1, 2])

        with col1:
            n_states = st.slider("éšçŠ¶æ€æ•°é‡", 2, 5, 3)
            hmm_mode = st.radio("çŠ¶æ€å®šä¹‰æ–¹å¼", ["é˜ˆå€¼ï¼ˆå›½æ ‡ï¼‰", "åˆ†ä½æ•°"], index=0)

            run_hmm = st.button("ğŸš€ æ‹Ÿåˆ HMM å¹¶æ¨æ–­å½“å‰çŠ¶æ€", use_container_width=True)

        with col2:
            st.markdown("**HMM è§‚æµ‹ç‰¹å¾ï¼š** " + ", ".join(feats))

        if run_hmm:
            with st.spinner("HMM è®­ç»ƒä¸­..."):
                obs = df[feats].dropna()
                pm25 = df.loc[obs.index, "PM2.5"].dropna()
                obs = obs.loc[pm25.index]

                hmm_model = HMMModel(n_states=n_states)

                # ç”¨ PM2.5 æ¥å®šä¹‰ state çš„é˜ˆå€¼/åˆ†ä½æ•°ï¼ˆåœ¨æ¨¡å‹é‡Œï¼‰
                hmm_model.fit(obs.values, pm25_values=pm25.values)

                # æ¨æ–­å…¨åºåˆ—çŠ¶æ€
                states = hmm_model.predict_states(obs.values)

                # âœ… å¯¹é½çŠ¶æ€å«ä¹‰ï¼šæŒ‰æ¯ä¸ª state çš„ PM2.5 å‡å€¼æ’åº
                state_means = {}
                for s in range(n_states):
                    state_means[s] = pm25.values[states == s].mean()

                sorted_states = sorted(state_means, key=state_means.get)
                mapped_names = []
                if n_states == 3 and hmm_mode.startswith("é˜ˆå€¼"):
                    mapped_names = ["ä¼˜è‰¯", "è½»åº¦æ±¡æŸ“", "é‡åº¦æ±¡æŸ“"]
                else:
                    mapped_names = [f"çŠ¶æ€{i+1}" for i in range(n_states)]

                mapping = {s: mapped_names[i] for i, s in enumerate(sorted_states)}
                current_state = mapping[states[-1]]

                st.success(f"å½“å‰éšçŠ¶æ€ï¼š**{current_state}**")
                mean_df = pd.DataFrame({
                    "state": list(state_means.keys()),
                    "PM2.5_mean": list(state_means.values())
                }).sort_values("PM2.5_mean")
                st.markdown("**å„çŠ¶æ€ PM2.5 å‡å€¼ï¼ˆç”¨äºè§£é‡Šå¯¹é½ï¼‰ï¼š**")
                st.dataframe(mean_df, use_container_width=True)

                st.markdown("#### ğŸ” çŠ¶æ€è½¬ç§»çŸ©é˜µ")
                trans = hmm_model.get_transition_matrix().copy()
                # é‡æ–°æŒ‰ mapping æ’åº/é‡å‘½å
                trans.index = [mapping.get(i, i) for i in trans.index]
                trans.columns = [mapping.get(i, i) for i in trans.columns]
                st.dataframe(trans, use_container_width=True)

                st.markdown("#### ğŸ“Œ æœ€è¿‘ 7 å¤©éšçŠ¶æ€åºåˆ—")
                last_idx = obs.index[-24*7:] if len(obs) >= 24*7 else obs.index
                last_states = states[-len(last_idx):]
                state_series = pd.Series([mapping[s] for s in last_states], index=last_idx)

                fig = go.Figure()
                fig.add_trace(go.Scatter(x=state_series.index, y=state_series.values, mode="lines"))
                fig.update_layout(height=250, margin=dict(t=20,b=0,l=0,r=0))
                st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")

    # =======================
    # 2) ARIMA çŸ­æœŸé¢„æµ‹
    # =======================
    st.markdown("### ğŸ”® è¶‹åŠ¿é¢„æµ‹ (ARIMA)")

    col_arima1, col_arima2 = st.columns([2, 1])
    with col_arima1:
        steps = st.slider("é¢„æµ‹æœªæ¥å°æ—¶æ•°", 12, 72, 24)
    with col_arima2:
        use_auto_select = st.checkbox("è‡ªåŠ¨é€‰æ‹©å‚æ•°ï¼ˆè¾ƒæ…¢ï¼‰", value=False, help="å–æ¶ˆå‹¾é€‰å°†ä½¿ç”¨é»˜è®¤å‚æ•°(1,1,1)ï¼Œé€Ÿåº¦æ›´å¿«")
    
    run_arima = st.button("ğŸ“ˆ ç”Ÿæˆ ARIMA é¢„æµ‹", type="primary", use_container_width=True)

    if run_arima:
        series = df["PM2.5"].dropna()
        
        # å¦‚æœæ•°æ®é‡å¤ªå¤§ï¼Œæç¤ºé™é‡‡æ ·
        if len(series) > 10000:
            st.info(f"ğŸ’¡ æ•°æ®é‡è¾ƒå¤§ï¼ˆ{len(series)}æ¡ï¼‰ï¼Œä¸ºåŠ å¿«é€Ÿåº¦å°†è‡ªåŠ¨é™é‡‡æ ·")
            # é™é‡‡æ ·åˆ°æœ€è¿‘10000æ¡
            series = series.iloc[-10000:]
        
        arima = ARIMAModel()

        # å¹³ç¨³æ€§æ£€éªŒ
        with st.spinner("æ­£åœ¨è¿›è¡Œå¹³ç¨³æ€§æ£€éªŒ..."):
            stat_res = arima.check_stationarity(series)
            st.write("ADF æ£€éªŒç»“æœï¼š", stat_res)

        # æ‹Ÿåˆ
        if use_auto_select:
            with st.spinner("æ­£åœ¨è‡ªåŠ¨é€‰æ‹©ARIMAå‚æ•°ï¼ˆè¿™å¯èƒ½éœ€è¦1-2åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰..."):
                arima.fit(series, auto_select=True)
                st.success(f"âœ… è‡ªåŠ¨é€‰æ‹©å‚æ•°ï¼šARIMA{arima.order}")
        else:
            with st.spinner("æ­£åœ¨æ‹ŸåˆARIMAæ¨¡å‹ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°(1,1,1)ï¼‰..."):
                arima.fit(series, auto_select=False, order=(1, 1, 1))
                st.success("âœ… ä½¿ç”¨é»˜è®¤å‚æ•°ï¼šARIMA(1,1,1)")

        # é¢„æµ‹ï¼ˆä¸¤ç§æ¨¡å¼éƒ½éœ€è¦æ‰§è¡Œï¼‰
        with st.spinner("æ­£åœ¨ç”Ÿæˆé¢„æµ‹..."):
            forecast_df = arima.predict(steps=steps, alpha=0.05)

        st.markdown("#### ğŸ“Š é¢„æµ‹æ›²çº¿ï¼ˆå«95%ç½®ä¿¡åŒºé—´ï¼‰")
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=series.index, y=series.values, mode="lines", name="å†å² PM2.5"
        ))
        fig.add_trace(go.Scatter(
            x=forecast_df.index, y=forecast_df["forecast"],
            mode="lines+markers", name="é¢„æµ‹"
        ))
        fig.add_trace(go.Scatter(
            x=forecast_df.index, y=forecast_df["upper"],
            mode="lines", name="ä¸Šç•Œ", line=dict(width=0),
            showlegend=False
        ))
        fig.add_trace(go.Scatter(
            x=forecast_df.index, y=forecast_df["lower"],
            mode="lines", name="ä¸‹ç•Œ", fill="tonexty",
            line=dict(width=0), showlegend=False
        ))
        fig.update_layout(height=350, margin=dict(t=20,b=0,l=0,r=0))
        st.plotly_chart(fig, use_container_width=True)

        with st.expander("ğŸ“„ ARIMA æ¨¡å‹æ‘˜è¦"):
            st.text(arima.get_summary())


def page_model_arena(df):
    """æ¨¡å‹ç«æŠ€åœºé¡µé¢ - å›å½’æ¨¡å‹å¯¹æ¯”"""
    st.markdown("## âš”ï¸ æ¨¡å‹ç«æŠ€åœº")
    st.info("ğŸ’¡ å¯¹æ¯”ä¸åŒå›å½’æ¨¡å‹çš„æ€§èƒ½ï¼Œå±•ç¤ºæ¨¡å‹é€‰æ‹©è¿‡ç¨‹ã€‚")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    features = [c for c in numeric_cols if c not in ['PM2.5', 'No', 'year', 'month', 'day', 'hour']]
    
    if len(features) == 0:
        st.warning("æœªæ‰¾åˆ°å¯ç”¨çš„ç‰¹å¾å˜é‡")
        return
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("#### âš™ï¸ å‚æ•°é…ç½®")
        selected_features = st.multiselect("é€‰æ‹©ç‰¹å¾å˜é‡", features, default=features[:4] if len(features) >= 4 else features)
        use_lasso_selection = st.checkbox("ä½¿ç”¨Lassoè¿›è¡Œç‰¹å¾ç­›é€‰", value=False)
        run_models = st.button("ğŸš€ è¿è¡Œæ‰€æœ‰æ¨¡å‹", type="primary", use_container_width=True)
    
    with col2:
        if run_models and selected_features:
            with st.spinner("æ­£åœ¨æ‹Ÿåˆæ¨¡å‹å¹¶è®¡ç®—è¯„ä¼°æŒ‡æ ‡..."):
                try:
                    X_raw = df[selected_features].dropna()
                    y = df.loc[X_raw.index, 'PM2.5'].dropna()
                    X_raw = X_raw.loc[y.index]
                    
                    # ç‰¹å¾é€‰æ‹©
                    selected_X = X_raw
                    if use_lasso_selection:
                        selector = FeatureSelector()
                        result = selector.lasso_selection(X_raw, y)
                        selected_X = X_raw[result['selected_features']]
                        st.success(f"Lassoç­›é€‰å‡º {result['n_selected']}/{result['n_total']} ä¸ªé‡è¦ç‰¹å¾")
                        
                        fig, ax = selector.plot_feature_importance(top_n=min(10, len(selected_features)))
                        st.pyplot(fig)
                    
                    # æ‹Ÿåˆå¤šä¸ªæ¨¡å‹
                    reg_models = RegressionModels()
                    evaluator = ModelEvaluator()
                    
                    models_results = {}
                    
                    # OLS
                    ols_model = reg_models.fit_ols(selected_X, y)
                    y_pred_ols = ols_model.predict(sm.add_constant(selected_X))
                    models_results['OLS'] = {
                        'y_true': y,
                        'y_pred': y_pred_ols,
                        'model': ols_model
                    }
                    
                    # Ridge
                    ridge_model = reg_models.fit_ridge(selected_X, y, cv=True)
                    y_pred_ridge = ridge_model.predict(reg_models.scaler.transform(selected_X.values))
                    models_results['Ridge'] = {
                        'y_true': y,
                        'y_pred': y_pred_ridge,
                        'model': ridge_model
                    }
                    
                    # Lasso
                    lasso_model = reg_models.fit_lasso(selected_X, y, cv=True)
                    y_pred_lasso = lasso_model.predict(reg_models.scaler.transform(selected_X.values))
                    models_results['Lasso'] = {
                        'y_true': y,
                        'y_pred': y_pred_lasso,
                        'model': lasso_model
                    }
                    
                    # GLM
                    glm_model = reg_models.fit_glm(selected_X, y)
                    y_pred_glm = glm_model.predict(selected_X)
                    models_results['GLM'] = {
                        'y_true': y,
                        'y_pred': y_pred_glm,
                        'model': glm_model.results
                    }
                    
                    # Bayesian Ridge
                    bayesian = BayesianModels()
                    bayesian.fit_bayesian_regression(selected_X, y)
                    y_pred_bayesian, y_std = bayesian.predict_bayesian_regression(selected_X)
                    models_results['Bayesian Ridge'] = {
                        'y_true': y,
                        'y_pred': y_pred_bayesian,
                        'model': bayesian.bayesian_ridge_model
                    }
                    
                    # æ¨¡å‹å¯¹æ¯”
                    st.markdown("#### ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
                    comparison_df = evaluator.compare_models(models_results, metric_type='regression')
                    st.dataframe(comparison_df.style.highlight_max(axis=0, subset=['RÂ²']).highlight_min(axis=0, subset=['AIC', 'BIC', 'RMSE', 'MAE']), use_container_width=True)
                    
                    # ä¿å­˜è¯„ä¼°ç»“æœåˆ°session_stateï¼ˆä¾›è¯„ä¼°ä¸­å¿ƒé¡µé¢ä½¿ç”¨ï¼‰
                    # æ³¨æ„ï¼šåªä¿å­˜æ•°æ®å’Œå¯¹æ¯”è¡¨æ ¼ï¼Œä¸ä¿å­˜æ¨¡å‹å¯¹è±¡å’Œevaluator
                    st.session_state['regression_evaluation'] = {
                        'comparison_df': comparison_df,
                        'models_results': {k: {
                            'y_true': np.array(v['y_true']).flatten(),
                            'y_pred': np.array(v['y_pred']).flatten()
                        } for k, v in models_results.items()},
                        'selected_features': selected_X.columns.tolist()
                    }
                    
                    # æ®‹å·®åˆ†æ
                    st.markdown("#### ğŸ“ˆ æ®‹å·®åˆ†æ")
                    model_choice = st.selectbox("é€‰æ‹©æ¨¡å‹æŸ¥çœ‹æ®‹å·®", list(models_results.keys()))
                    if model_choice:
                        fig = evaluator.plot_residuals(
                            models_results[model_choice]['y_true'],
                            models_results[model_choice]['y_pred']
                        )
                        st.pyplot(fig)
                        
                        # Durbin-Watsonæ£€éªŒ
                        dw_result = evaluator.durbin_watson_test(
                            models_results[model_choice]['y_true'] - models_results[model_choice]['y_pred']
                        )
                        st.info(f"Durbin-Watsonç»Ÿè®¡é‡: {dw_result['dw_statistic']:.4f} - {dw_result['interpretation']}")
                    
                    # è´å¶æ–¯åéªŒåˆ†å¸ƒ
                    st.markdown("#### ğŸ² è´å¶æ–¯æ–¹æ³•ï¼šå‚æ•°åéªŒåˆ†å¸ƒ")
                    fig, ax = bayesian.plot_posterior(feature_names=selected_X.columns.tolist())
                    st.pyplot(fig)
                    
                except Exception as e:
                    st.error(f"æ¨¡å‹æ‹Ÿåˆå¤±è´¥: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())


def page_classification(df):
    """åˆ†ç±»ä¸çŠ¶æ€é¡µé¢ - åˆ†ç±»æ¨¡å‹å¯¹æ¯”"""
    st.markdown("## ğŸ¯ åˆ†ç±»ä¸çŠ¶æ€")
    st.info("ğŸ’¡ å¯¹æ¯”Logistic Regressionã€Naive Bayeså’ŒHMMçš„åˆ†ç±»æ€§èƒ½ã€‚")
    
    if 'PM2.5' not in df.columns:
        st.error("æ•°æ®ä¸­æœªæ‰¾åˆ°PM2.5åˆ—")
        return
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    features = [c for c in numeric_cols if c not in ['PM2.5', 'No', 'year', 'month', 'day', 'hour']]
    
    if len(features) == 0:
        st.warning("æœªæ‰¾åˆ°å¯ç”¨çš„ç‰¹å¾å˜é‡")
        return
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.markdown("#### âš™ï¸ å‚æ•°é…ç½®")
        selected_features = st.multiselect("é€‰æ‹©ç‰¹å¾å˜é‡", features, default=features[:4] if len(features) >= 4 else features)
        run_classification = st.button("ğŸš€ è¿è¡Œåˆ†ç±»æ¨¡å‹", type="primary", use_container_width=True)
    
    with col2:
        if run_classification and selected_features:
            with st.spinner("æ­£åœ¨è®­ç»ƒåˆ†ç±»æ¨¡å‹..."):
                try:
                    X = df[selected_features].dropna()
                    y_pm25 = df.loc[X.index, 'PM2.5'].dropna()
                    X = X.loc[y_pm25.index]
                    
                    # åˆå§‹åŒ–åˆ†ç±»æ¨¡å‹
                    clf_models = ClassificationModels()
                    evaluator = ModelEvaluator()
                    
                    # Logistic Regression
                    clf_models.fit_logistic(X, pm25_values=y_pm25.values)
                    y_pred_logistic = clf_models.predict_logistic(X)
                    y_proba_logistic = clf_models.predict_proba_logistic(X)
                    
                    # Naive Bayes
                    clf_models.fit_naive_bayes(X, pm25_values=y_pm25.values)
                    y_pred_nb = clf_models.predict_naive_bayes(X)
                    y_proba_nb = clf_models.predict_proba_naive_bayes(X)
                    
                    # è½¬æ¢ä¸ºåˆ†ç±»æ ‡ç­¾ï¼ˆç”¨äºè¯„ä¼°ï¼‰
                    y_true = clf_models._pm25_to_category(y_pm25.values)
                    
                    # è¯„ä¼°
                    eval_logistic = clf_models.evaluate(y_true, y_pred_logistic, y_proba_logistic, "Logistic Regression")
                    eval_nb = clf_models.evaluate(y_true, y_pred_nb, y_proba_nb, "Naive Bayes")
                    
                    # HMMï¼ˆä½¿ç”¨ç°æœ‰HMMæ¨¡å—ï¼‰
                    hmm_feats = get_hmm_features(df)
                    if len(hmm_feats) > 0:
                        hmm_obs = df[hmm_feats].loc[X.index].dropna()
                        hmm_pm25 = y_pm25.loc[hmm_obs.index]
                        hmm_obs = hmm_obs.loc[hmm_pm25.index]
                        
                        hmm_model = HMMModel(n_states=3)
                        hmm_model.fit(hmm_obs.values, pm25_values=hmm_pm25.values)
                        hmm_states = hmm_model.predict_states(hmm_obs.values)
                        
                        # å¯¹é½HMMçŠ¶æ€å’Œåˆ†ç±»æ ‡ç­¾
                        state_means = {}
                        for s in range(3):
                            state_means[s] = hmm_pm25.values[hmm_states == s].mean() if np.sum(hmm_states == s) > 0 else 0
                        sorted_states = sorted(state_means, key=state_means.get)
                        state_mapping = {sorted_states[i]: i for i in range(3)}
                        hmm_labels = np.array([state_mapping[s] for s in hmm_states])
                        y_true_hmm = clf_models._pm25_to_category(hmm_pm25.values)
                        eval_hmm = evaluator.classification_metrics(y_true_hmm, hmm_labels)
                    else:
                        eval_hmm = None
                    
                    # å±•ç¤ºç»“æœ
                    st.markdown("#### ğŸ“Š åˆ†ç±»æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
                    comparison_data = {
                        'Logistic Regression': {
                            'Accuracy': eval_logistic['accuracy'],
                            'Precision (Macro)': eval_logistic['precision_macro'],
                            'Recall (Macro)': eval_logistic['recall_macro'],
                            'F1-Score (Macro)': eval_logistic['f1_macro'],
                            'AUC': eval_logistic['auc_score']
                        },
                        'Naive Bayes': {
                            'Accuracy': eval_nb['accuracy'],
                            'Precision (Macro)': eval_nb['precision_macro'],
                            'Recall (Macro)': eval_nb['recall_macro'],
                            'F1-Score (Macro)': eval_nb['f1_macro'],
                            'AUC': eval_nb['auc_score']
                        }
                    }
                    
                    if eval_hmm:
                        comparison_data['HMM'] = {
                            'Accuracy': eval_hmm['accuracy'],
                            'Precision (Macro)': eval_hmm['precision_macro'],
                            'Recall (Macro)': eval_hmm['recall_macro'],
                            'F1-Score (Macro)': eval_hmm['f1_macro'],
                            'AUC': eval_hmm['auc_score']
                        }
                    
                    comparison_df = pd.DataFrame(comparison_data).T
                    st.dataframe(comparison_df.style.highlight_max(axis=0), use_container_width=True)
                    
                    # ä¿å­˜è¯„ä¼°ç»“æœåˆ°session_stateï¼ˆä¾›è¯„ä¼°ä¸­å¿ƒé¡µé¢ä½¿ç”¨ï¼‰
                    st.session_state['classification_evaluation'] = {
                        'comparison_df': comparison_df,
                        'y_true': np.array(y_true).flatten(),
                        'y_pred_logistic': np.array(y_pred_logistic).flatten(),
                        'y_pred_nb': np.array(y_pred_nb).flatten(),
                        'y_proba_logistic': np.array(y_proba_logistic),
                        'y_proba_nb': np.array(y_proba_nb),
                        'eval_logistic': eval_logistic,
                        'eval_nb': eval_nb,
                        'eval_hmm': eval_hmm,
                        'class_names': clf_models.get_class_names()
                    }
                    
                    # æ··æ·†çŸ©é˜µå¯¹æ¯”
                    col_cm1, col_cm2 = st.columns(2)
                    with col_cm1:
                        st.markdown("**Logistic Regression æ··æ·†çŸ©é˜µ**")
                        fig, ax = evaluator.plot_confusion_matrix(y_true, y_pred_logistic, clf_models.get_class_names())
                        st.pyplot(fig)
                    
                    with col_cm2:
                        st.markdown("**Naive Bayes æ··æ·†çŸ©é˜µ**")
                        fig, ax = evaluator.plot_confusion_matrix(y_true, y_pred_nb, clf_models.get_class_names())
                        st.pyplot(fig)
                    
                    # ROCæ›²çº¿å¯¹æ¯”
                    st.markdown("#### ğŸ“ˆ ROCæ›²çº¿å¯¹æ¯”")
                    fig, ax = evaluator.plot_roc_curve(y_true, y_proba_logistic, clf_models.get_class_names())
                    st.pyplot(fig)
                    
                except Exception as e:
                    st.error(f"åˆ†ç±»æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())


def page_evaluation_center(df):
    """è¯„ä¼°ä¸­å¿ƒé¡µé¢ - ç»Ÿä¸€è¯„ä¼°æ‰€æœ‰æ¨¡å‹"""
    st.markdown("## ğŸ“‹ è¯„ä¼°ä¸­å¿ƒ")
    st.info("ğŸ’¡ ç»Ÿä¸€å±•ç¤ºæ‰€æœ‰æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡å’Œæ€§èƒ½å¯¹æ¯”ã€‚")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¯„ä¼°ç»“æœ
    has_regression = 'regression_evaluation' in st.session_state
    has_classification = 'classification_evaluation' in st.session_state
    
    if not has_regression and not has_classification:
        st.warning("""
        **âš ï¸ æš‚æ— è¯„ä¼°ç»“æœ**
        
        è¯·å…ˆåœ¨å…¶ä»–é¡µé¢è¿è¡Œæ¨¡å‹ï¼š
        - **å›å½’æ¨¡å‹**ï¼šå‰å¾€"âš”ï¸ æ¨¡å‹ç«æŠ€åœº"é¡µé¢ï¼Œé€‰æ‹©ç‰¹å¾å¹¶è¿è¡Œæ‰€æœ‰æ¨¡å‹
        - **åˆ†ç±»æ¨¡å‹**ï¼šå‰å¾€"ğŸ¯ åˆ†ç±»ä¸çŠ¶æ€"é¡µé¢ï¼Œé€‰æ‹©ç‰¹å¾å¹¶è¿è¡Œåˆ†ç±»æ¨¡å‹
        
        è¿è¡Œåï¼Œè¯„ä¼°ç»“æœå°†è‡ªåŠ¨æ˜¾ç¤ºåœ¨è¿™é‡Œã€‚
        """)
        return
    
    # =======================
    # 1. å›å½’æ¨¡å‹è¯„ä¼°
    # =======================
    st.markdown("### ğŸ“Š å›å½’æ¨¡å‹è¯„ä¼°")
    
    if has_regression:
        reg_eval = st.session_state['regression_evaluation']
        comparison_df = reg_eval['comparison_df']
        models_results = reg_eval['models_results']
        evaluator = ModelEvaluator()  # é‡æ–°åˆ›å»ºevaluator
        
        # è¯„ä¼°æŒ‡æ ‡å¯¹æ¯”è¡¨
        st.markdown("#### ğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨")
        st.dataframe(
            comparison_df.style.highlight_max(axis=0, subset=['RÂ²'])
                          .highlight_min(axis=0, subset=['AIC', 'BIC', 'RMSE', 'MAE']),
            use_container_width=True
        )
        
        # æ¨¡å‹é€‰æ‹©å»ºè®®
        st.markdown("#### ğŸ’¡ æ¨¡å‹é€‰æ‹©å»ºè®®")
        best_r2 = comparison_df['RÂ²'].idxmax()
        best_aic = comparison_df['AIC'].idxmin() if 'AIC' in comparison_df.columns and comparison_df['AIC'].notna().any() else None
        
        col_rec1, col_rec2 = st.columns(2)
        with col_rec1:
            st.success(f"**æœ€ä½³RÂ²æ¨¡å‹**ï¼š{best_r2} (RÂ² = {comparison_df.loc[best_r2, 'RÂ²']:.4f})")
        with col_rec2:
            if best_aic:
                st.success(f"**æœ€ä½³AICæ¨¡å‹**ï¼š{best_aic} (AIC = {comparison_df.loc[best_aic, 'AIC']:.2f})")
        
        # æ®‹å·®åˆ†ææ±‡æ€»
        st.markdown("#### ğŸ“‰ æ®‹å·®åˆ†ææ±‡æ€»")
        model_choice = st.selectbox("é€‰æ‹©æ¨¡å‹æŸ¥çœ‹æ®‹å·®åˆ†æ", list(models_results.keys()), key='reg_residual_choice')
        if model_choice:
            y_true = models_results[model_choice]['y_true']
            y_pred = models_results[model_choice]['y_pred']
            
            col_res1, col_res2 = st.columns([2, 1])
            with col_res1:
                fig = evaluator.plot_residuals(y_true, y_pred)
                st.pyplot(fig)
            
            with col_res2:
                # Durbin-Watsonæ£€éªŒ
                residuals = y_true - y_pred
                dw_result = evaluator.durbin_watson_test(residuals)
                st.markdown("**Durbin-Watsonæ£€éªŒ**")
                st.metric("DWç»Ÿè®¡é‡", f"{dw_result['dw_statistic']:.4f}")
                st.info(f"**{dw_result['interpretation']}**")
                
                # æ®‹å·®ç»Ÿè®¡
                st.markdown("**æ®‹å·®ç»Ÿè®¡**")
                st.metric("å‡å€¼", f"{np.mean(residuals):.4f}")
                st.metric("æ ‡å‡†å·®", f"{np.std(residuals):.4f}")
    else:
        st.info('ğŸ’¡ è¯·å‰å¾€"âš”ï¸ æ¨¡å‹ç«æŠ€åœº"é¡µé¢è¿è¡Œå›å½’æ¨¡å‹åï¼Œè¯„ä¼°ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œã€‚')
    
    st.markdown("---")
    
    # =======================
    # 2. åˆ†ç±»æ¨¡å‹è¯„ä¼°
    # =======================
    st.markdown("### ğŸ¯ åˆ†ç±»æ¨¡å‹è¯„ä¼°")
    
    if has_classification:
        clf_eval = st.session_state['classification_evaluation']
        comparison_df = clf_eval['comparison_df']
        evaluator = ModelEvaluator()  # é‡æ–°åˆ›å»ºevaluator
        class_names = clf_eval['class_names']
        
        # è¯„ä¼°æŒ‡æ ‡å¯¹æ¯”è¡¨
        st.markdown("#### ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨")
        st.dataframe(
            comparison_df.style.highlight_max(axis=0),
            use_container_width=True
        )
        
        # æ¨¡å‹é€‰æ‹©å»ºè®®
        st.markdown("#### ğŸ’¡ æ¨¡å‹é€‰æ‹©å»ºè®®")
        best_accuracy = comparison_df['Accuracy'].idxmax()
        best_f1 = comparison_df['F1-Score (Macro)'].idxmax() if 'F1-Score (Macro)' in comparison_df.columns else None
        best_auc = comparison_df['AUC'].idxmax() if 'AUC' in comparison_df.columns and comparison_df['AUC'].notna().any() else None
        
        col_clf1, col_clf2, col_clf3 = st.columns(3)
        with col_clf1:
            st.success(f"**æœ€ä½³å‡†ç¡®ç‡**ï¼š{best_accuracy}\n(Accuracy = {comparison_df.loc[best_accuracy, 'Accuracy']:.4f})")
        with col_clf2:
            if best_f1:
                st.success(f"**æœ€ä½³F1-Score**ï¼š{best_f1}\n(F1 = {comparison_df.loc[best_f1, 'F1-Score (Macro)']:.4f})")
        with col_clf3:
            if best_auc:
                st.success(f"**æœ€ä½³AUC**ï¼š{best_auc}\n(AUC = {comparison_df.loc[best_auc, 'AUC']:.4f})")
        
        # æ··æ·†çŸ©é˜µå¯¹æ¯”
        st.markdown("#### ğŸ¯ æ··æ·†çŸ©é˜µå¯¹æ¯”")
        col_cm1, col_cm2, col_cm3 = st.columns(3)
        
        with col_cm1:
            st.markdown("**Logistic Regression**")
            fig, ax = evaluator.plot_confusion_matrix(
                clf_eval['y_true'],
                clf_eval['y_pred_logistic'],
                class_names
            )
            st.pyplot(fig)
        
        with col_cm2:
            st.markdown("**Naive Bayes**")
            fig, ax = evaluator.plot_confusion_matrix(
                clf_eval['y_true'],
                clf_eval['y_pred_nb'],
                class_names
            )
            st.pyplot(fig)
        
        with col_cm3:
            if 'eval_hmm' in clf_eval and clf_eval['eval_hmm'] is not None:
                st.markdown("**HMM**")
                # HMMçš„æ··æ·†çŸ©é˜µï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                st.info("HMMæ··æ·†çŸ©é˜µéœ€åœ¨åˆ†ç±»ä¸çŠ¶æ€é¡µé¢æŸ¥çœ‹")
            else:
                st.info("HMMç»“æœæœªå¯ç”¨")
        
        # ROCæ›²çº¿å¯¹æ¯”
        st.markdown("#### ğŸ“ˆ ROCæ›²çº¿å¯¹æ¯”")
        try:
            # ç»˜åˆ¶å¤šä¸ªæ¨¡å‹çš„ROCæ›²çº¿
            fig, ax = plt.subplots(figsize=(10, 6))
            
            # Logistic Regression
            from sklearn.metrics import roc_curve, roc_auc_score
            y_true = clf_eval['y_true']
            y_proba_log = clf_eval['y_proba_logistic']
            
            # å¤šåˆ†ç±»ROCï¼ˆä½¿ç”¨one-vs-restï¼‰
            n_classes = len(class_names)
            if n_classes == 2:
                fpr, tpr, _ = roc_curve(y_true, y_proba_log[:, 1])
                auc = roc_auc_score(y_true, y_proba_log[:, 1])
                ax.plot(fpr, tpr, label=f'Logistic Regression (AUC = {auc:.3f})')
            else:
                for i in range(n_classes):
                    y_binary = (y_true == i).astype(int)
                    if len(np.unique(y_binary)) > 1:
                        fpr, tpr, _ = roc_curve(y_binary, y_proba_log[:, i])
                        auc = roc_auc_score(y_binary, y_proba_log[:, i])
                        ax.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {auc:.3f})')
            
            # Naive Bayes
            y_proba_nb = clf_eval['y_proba_nb']
            if n_classes == 2:
                fpr, tpr, _ = roc_curve(y_true, y_proba_nb[:, 1])
                auc = roc_auc_score(y_true, y_proba_nb[:, 1])
                ax.plot(fpr, tpr, linestyle='--', label=f'Naive Bayes (AUC = {auc:.3f})')
            else:
                for i in range(n_classes):
                    y_binary = (y_true == i).astype(int)
                    if len(np.unique(y_binary)) > 1:
                        fpr, tpr, _ = roc_curve(y_binary, y_proba_nb[:, i])
                        auc = roc_auc_score(y_binary, y_proba_nb[:, i])
                        ax.plot(fpr, tpr, linestyle='--', label=f'{class_names[i]} (NB, AUC = {auc:.3f})')
            
            ax.plot([0, 1], [0, 1], 'k--', label='éšæœºçŒœæµ‹')
            ax.set_xlabel('å‡æ­£ç‡ (FPR)')
            ax.set_ylabel('çœŸæ­£ç‡ (TPR)')
            ax.set_title('ROCæ›²çº¿å¯¹æ¯”')
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
        except Exception as e:
            st.warning(f"ROCæ›²çº¿ç»˜åˆ¶å¤±è´¥: {str(e)}")
            # ä½¿ç”¨evaluatorçš„æ–¹æ³•
            try:
                fig, ax = evaluator.plot_roc_curve(y_true, y_proba_log, class_names)
                st.pyplot(fig)
            except:
                pass
    
    else:
        st.info('ğŸ’¡ è¯·å‰å¾€"ğŸ¯ åˆ†ç±»ä¸çŠ¶æ€"é¡µé¢è¿è¡Œåˆ†ç±»æ¨¡å‹åï¼Œè¯„ä¼°ç»“æœå°†æ˜¾ç¤ºåœ¨è¿™é‡Œã€‚')
    
    st.markdown("---")
    
    # =======================
    # 3. ç»¼åˆæ€»ç»“
    # =======================
    st.markdown("### ğŸ“‹ ç»¼åˆè¯„ä¼°æ€»ç»“")
    
    if has_regression and has_classification:
        st.success("""
        **âœ… æ‰€æœ‰æ¨¡å‹è¯„ä¼°å®Œæˆ**
        
        **å›å½’æ¨¡å‹å»ºè®®**ï¼š
        - æ ¹æ®RÂ²ã€AIC/BICæŒ‡æ ‡é€‰æ‹©æœ€ä½³å›å½’æ¨¡å‹
        - å…³æ³¨æ®‹å·®åˆ†æï¼Œç¡®ä¿æ¨¡å‹å‡è®¾æ»¡è¶³
        
        **åˆ†ç±»æ¨¡å‹å»ºè®®**ï¼š
        - æ ¹æ®Accuracyã€F1-Scoreã€AUCé€‰æ‹©æœ€ä½³åˆ†ç±»æ¨¡å‹
        - å…³æ³¨æ··æ·†çŸ©é˜µï¼Œåˆ†æå„ç±»åˆ«çš„åˆ†ç±»æ€§èƒ½
        
        **æ¨¡å‹é€‰æ‹©åŸåˆ™**ï¼š
        1. å›å½’æ¨¡å‹ï¼šä¼˜å…ˆè€ƒè™‘RÂ²é«˜ã€AIC/BICä½çš„æ¨¡å‹
        2. åˆ†ç±»æ¨¡å‹ï¼šä¼˜å…ˆè€ƒè™‘Accuracyå’ŒF1-Scoreé«˜çš„æ¨¡å‹
        3. ç»¼åˆè€ƒè™‘ï¼šç»“åˆå®é™…åº”ç”¨åœºæ™¯å’Œæ¨¡å‹å¤æ‚åº¦
        """)
    elif has_regression:
        st.info("å›å½’æ¨¡å‹è¯„ä¼°å·²å®Œæˆï¼Œè¯·è¿è¡Œåˆ†ç±»æ¨¡å‹ä»¥è·å¾—å®Œæ•´è¯„ä¼°ã€‚")
    elif has_classification:
        st.info("åˆ†ç±»æ¨¡å‹è¯„ä¼°å·²å®Œæˆï¼Œè¯·è¿è¡Œå›å½’æ¨¡å‹ä»¥è·å¾—å®Œæ•´è¯„ä¼°ã€‚")


# ==========================================
# 4. ä¸»ç¨‹åºå…¥å£
# ==========================================

def main():
    # è·¯å¾„è®¾ç½®
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    default_data_path = os.path.normpath(os.path.join(current_script_dir, '..', 'Data', 'PRSA_data_2010.1.1-2014.12.31.csv'))

    with st.sidebar:
        st.image("https://cdn-icons-png.flaticon.com/512/3208/3208728.png", width=60)
        st.markdown("### ç©ºæ°”è´¨é‡ç›‘æµ‹ç³»ç»Ÿ")
        st.markdown("Version 3.0 | Ultimate Edition")
        
        st.markdown("---")
        
        # æ¼‚äº®çš„èœå•ç»„ä»¶
        if HAS_OPTION_MENU:
            selected = option_menu(
                menu_title=None,
                options=["æ•°æ®æ´å¯Ÿ", "å½’å› åˆ†æ", "âš”ï¸ æ¨¡å‹ç«æŠ€åœº", "ğŸ¯ åˆ†ç±»ä¸çŠ¶æ€", "é¢„è­¦ä¸­å¿ƒ", "ğŸ“‹ è¯„ä¼°ä¸­å¿ƒ"],
                icons=["bar-chart-fill", "search", "trophy", "target", "shield-exclamation", "clipboard-data"],
                menu_icon="cast",
                default_index=0,
                styles={
                    "container": {"padding": "0!important", "background-color": "#fafafa"},
                    "icon": {"color": "#2980b9", "font-size": "16px"}, 
                    "nav-link": {"font-size": "14px", "text-align": "left", "margin":"0px", "--hover-color": "#eee"},
                    "nav-link-selected": {"background-color": "#3498db"},
                }
            )
        else:
            selected = st.radio("å¯¼èˆª", ["æ•°æ®æ´å¯Ÿ", "å½’å› åˆ†æ", "âš”ï¸ æ¨¡å‹ç«æŠ€åœº", "ğŸ¯ åˆ†ç±»ä¸çŠ¶æ€", "é¢„è­¦ä¸­å¿ƒ", "ğŸ“‹ è¯„ä¼°ä¸­å¿ƒ"])
        
        st.markdown("---")
        
        # æ•°æ®åŠ è½½åŒº
        with st.expander("ğŸ“‚ æ•°æ®ç®¡ç†", expanded=True):
            # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
            st.markdown("#### ğŸ“¤ ä¸Šä¼ æ•°æ®æ–‡ä»¶")
            uploaded_file = st.file_uploader(
                "é€‰æ‹© CSV æ–‡ä»¶",
                type=['csv'],
                help="æ”¯æŒæœ€å¤§200MBçš„CSVæ–‡ä»¶ï¼Œå¿…é¡»åŒ…å«PM2.5åˆ—"
            )
            
            # æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤ºå’Œç¡®è®¤
            if uploaded_file is not None:
                # æ˜¾ç¤ºæ–‡ä»¶åŸºæœ¬ä¿¡æ¯
                file_size_mb = uploaded_file.size / (1024 * 1024)
                
                col_info1, col_info2, col_info3 = st.columns(3)
                with col_info1:
                    st.metric("ğŸ“„ æ–‡ä»¶å", uploaded_file.name[:20] + "..." if len(uploaded_file.name) > 20 else uploaded_file.name)
                with col_info2:
                    st.metric("ğŸ“Š æ–‡ä»¶å¤§å°", f"{file_size_mb:.2f} MB")
                with col_info3:
                    st.metric("ğŸ“‹ æ–‡ä»¶ç±»å‹", "CSV")
                
                # æ–‡ä»¶éªŒè¯å’Œé¢„è§ˆ
                with st.expander("ğŸ” æ–‡ä»¶é¢„è§ˆä¸éªŒè¯", expanded=True):
                    try:
                        # è¯»å–å‰å‡ è¡Œè¿›è¡Œé¢„è§ˆï¼ˆä½¿ç”¨getvalue()è·å–å‰¯æœ¬ï¼Œä¸å½±å“åŸæ–‡ä»¶æŒ‡é’ˆï¼‰
                        import io
                        file_content = uploaded_file.getvalue()
                        preview_df = pd.read_csv(io.StringIO(file_content.decode('utf-8')), nrows=5)
                        
                        st.markdown("**å‰5è¡Œæ•°æ®é¢„è§ˆï¼š**")
                        st.dataframe(preview_df, use_container_width=True)
                        
                        # æ£€æŸ¥å¿…éœ€åˆ—
                        columns_lower = [col.lower() for col in preview_df.columns]
                        has_pm25 = any('pm2.5' in col or 'pm25' in col or 'pm 2.5' in col for col in columns_lower)
                        has_date = any('date' in col or 'time' in col or 'datetime' in col for col in columns_lower)
                        
                        col_check1, col_check2 = st.columns(2)
                        with col_check1:
                            if has_pm25:
                                st.success("âœ… æ£€æµ‹åˆ°PM2.5åˆ—")
                            else:
                                st.error("âŒ æœªæ£€æµ‹åˆ°PM2.5åˆ—ï¼ˆå¿…éœ€ï¼‰")
                        with col_check2:
                            if has_date:
                                st.success("âœ… æ£€æµ‹åˆ°æ—¥æœŸåˆ—")
                            else:
                                st.warning("âš ï¸ æœªæ£€æµ‹åˆ°æ—¥æœŸåˆ—ï¼ˆæ—¶é—´åºåˆ—åŠŸèƒ½å¯èƒ½å—é™ï¼‰")
                        
                        # æ˜¾ç¤ºåˆ—ä¿¡æ¯
                        st.markdown(f"**æ•°æ®åˆ— ({len(preview_df.columns)}ä¸ª)ï¼š**")
                        st.text(", ".join(preview_df.columns.tolist()[:10]))
                        if len(preview_df.columns) > 10:
                            st.text(f"... è¿˜æœ‰ {len(preview_df.columns) - 10} ä¸ªåˆ—")
                        
                    except Exception as e:
                        st.error(f"âš ï¸ æ–‡ä»¶é¢„è§ˆå¤±è´¥: {str(e)}")
                        st.info("ğŸ’¡ æ–‡ä»¶å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„CSVæ ¼å¼ï¼Œä½†ä»å¯å°è¯•åŠ è½½")
                
                # ç¡®è®¤åŠ è½½æŒ‰é’®
                st.markdown("---")
                col_btn1, col_btn2 = st.columns([1, 1])
                
                with col_btn1:
                    if st.button("âœ… ç¡®è®¤åŠ è½½æ­¤æ–‡ä»¶", type="primary", use_container_width=True):
                        with st.spinner("æ­£åœ¨åŠ è½½æ–‡ä»¶..."):
                            try:
                                # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                                uploaded_file.seek(0)
                                
                                # æ˜¾ç¤ºåŠ è½½è¿›åº¦ï¼ˆæ¨¡æ‹Ÿï¼‰
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                status_text.text("ğŸ“¥ è¯»å–æ–‡ä»¶...")
                                progress_bar.progress(20)
                                
                                # åŠ è½½æ•°æ®
                                df_uploaded = load_data(uploaded_file)
                                progress_bar.progress(60)
                                
                                if df_uploaded is not None:
                                    status_text.text("âœ… éªŒè¯æ•°æ®æ ¼å¼...")
                                    progress_bar.progress(80)
                                    
                                    # ä¿å­˜æ•°æ®
                                    st.session_state['data'] = df_uploaded
                                    if 'processed_data' in st.session_state:
                                        del st.session_state['processed_data']
                                    
                                    progress_bar.progress(100)
                                    status_text.text("âœ… åŠ è½½å®Œæˆï¼")
                                    
                                    # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                                    st.success(f"""
                                    **âœ… æ–‡ä»¶åŠ è½½æˆåŠŸï¼**
                                    
                                    - ğŸ“„ æ–‡ä»¶å: {uploaded_file.name}
                                    - ğŸ“Š æ•°æ®é‡: {len(df_uploaded):,} æ¡è®°å½•
                                    - ğŸ“‹ åˆ—æ•°: {len(df_uploaded.columns)} ä¸ª
                                    - ğŸŒ«ï¸ PM2.5èŒƒå›´: {df_uploaded['PM2.5'].min():.1f} ~ {df_uploaded['PM2.5'].max():.1f} Î¼g/mÂ³
                                    """)
                                    
                                    # å»¶è¿Ÿååˆ·æ–°é¡µé¢
                                    import time
                                    time.sleep(1)
                                    st.rerun()
                                else:
                                    progress_bar.progress(0)
                                    status_text.empty()
                                    st.error("""
                                    **âŒ æ–‡ä»¶åŠ è½½å¤±è´¥**
                                    
                                    å¯èƒ½çš„åŸå› ï¼š
                                    - æ–‡ä»¶ä¸åŒ…å«PM2.5åˆ—ï¼ˆå¿…éœ€ï¼‰
                                    - æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®
                                    - æ–‡ä»¶ç¼–ç é—®é¢˜
                                    
                                    ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼Œç¡®ä¿åŒ…å«PM2.5åˆ—
                                    """)
                            except Exception as e:
                                progress_bar.progress(0)
                                status_text.empty()
                                st.error(f"""
                                **âŒ æ–‡ä»¶åŠ è½½å‡ºé”™**
                                
                                é”™è¯¯ä¿¡æ¯: {str(e)}
                                
                                ğŸ’¡ è¯·æ£€æŸ¥ï¼š
                                - æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„CSVæ ¼å¼
                                - æ–‡ä»¶ç¼–ç æ˜¯å¦ä¸ºUTF-8
                                - æ–‡ä»¶æ˜¯å¦æŸå
                                """)
                                import traceback
                                with st.expander("ğŸ” æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                                    st.code(traceback.format_exc())
                
                with col_btn2:
                    if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                        # æ¸…é™¤ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆé€šè¿‡åˆ·æ–°ï¼‰
                        st.session_state.pop('uploaded_file', None)
                        st.rerun()
            
            else:
                # æœªä¸Šä¼ æ–‡ä»¶æ—¶çš„æç¤º
                st.info("ğŸ’¡ è¯·ä¸Šä¼ CSVæ–‡ä»¶ï¼Œæˆ–ä½¿ç”¨ä¸‹æ–¹çš„æµ‹è¯•æ•°æ®")
            
            st.markdown("---")
            st.markdown("### ğŸ§¹ é¢„å¤„ç†è®¾ç½®")
            st.caption("ğŸ’¡ ä¿®æ”¹è®¾ç½®åä¼šè‡ªåŠ¨é‡æ–°å¤„ç†æ•°æ®")
            
            # åˆå§‹åŒ–é¢„å¤„ç†è®¾ç½®ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if 'preprocessing_settings' not in st.session_state:
                st.session_state['preprocessing_settings'] = {
                    'missing_method': 'interpolation',
                    'outlier_method': '3sigma',
                    'do_log': False
                }
            
            # é¢„å¤„ç†è®¾ç½®é€‰æ‹©
            missing_method = st.selectbox(
                "ç¼ºå¤±å€¼å¤„ç†",
                ["interpolation", "drop"],
                index=0 if st.session_state['preprocessing_settings']['missing_method'] == 'interpolation' else 1,
                help="interpolation: çº¿æ€§æ’å€¼å¡«è¡¥ç¼ºå¤±å€¼ | drop: åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ"
            )
            outlier_method = st.selectbox(
                "å¼‚å¸¸å€¼å¤„ç†",
                ["3sigma", "iqr", "none"],
                index=["3sigma", "iqr", "none"].index(st.session_state['preprocessing_settings']['outlier_method']),
                help="3sigma: 3å€æ ‡å‡†å·®åŸåˆ™ | iqr: å››åˆ†ä½è·æ–¹æ³• | none: ä¸å¤„ç†å¼‚å¸¸å€¼"
            )
            do_log = st.checkbox(
                "å¯¹ PM2.5 åš Log å˜æ¢ï¼ˆç”¨äºæ£€éªŒ/å»ºæ¨¡å¯¹æ¯”ï¼‰",
                value=st.session_state['preprocessing_settings']['do_log'],
                help="å¯¹PM2.5è¿›è¡Œå¯¹æ•°å˜æ¢ï¼Œä½¿å…¶æ›´æ¥è¿‘æ­£æ€åˆ†å¸ƒ"
            )
            
            # æ£€æŸ¥è®¾ç½®æ˜¯å¦æ”¹å˜
            settings_changed = (
                missing_method != st.session_state['preprocessing_settings']['missing_method'] or
                outlier_method != st.session_state['preprocessing_settings']['outlier_method'] or
                do_log != st.session_state['preprocessing_settings']['do_log']
            )
            
            if settings_changed:
                # æ›´æ–°è®¾ç½®
                st.session_state['preprocessing_settings'] = {
                    'missing_method': missing_method,
                    'outlier_method': outlier_method,
                    'do_log': do_log
                }
                # æ¸…é™¤å·²å¤„ç†çš„æ•°æ®ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°å¤„ç†
                if 'processed_data' in st.session_state:
                    del st.session_state['processed_data']
                st.rerun()
            
            st.markdown("---")
            st.markdown("### ğŸ§ª æˆ–ä½¿ç”¨æµ‹è¯•æ•°æ®")
            st.caption("å¿«é€ŸåŠ è½½é¡¹ç›®è‡ªå¸¦çš„UCI Beijing PM2.5æ•°æ®é›†ï¼ˆ2010-2014å¹´ï¼‰")
            if st.button("ğŸ”„ åŠ è½½æµ‹è¯•æ•°æ®", use_container_width=True):
                if os.path.exists(default_data_path):
                    st.session_state['data'] = load_data(default_data_path)
                    if 'processed_data' in st.session_state: 
                        del st.session_state['processed_data']
                    st.success("âœ… æµ‹è¯•æ•°æ®åŠ è½½æˆåŠŸ")
                    st.rerun()
                else:
                    # å°è¯•å…¶ä»–å¯èƒ½çš„æ–‡ä»¶å
                    alternative_paths = [
                        os.path.normpath(os.path.join(current_script_dir, '..', 'Data', 'PRSA_data.csv')),
                        os.path.normpath(os.path.join(current_script_dir, '..', 'Data', 'beijing+pm2+5+data', 'PRSA_data.csv')),
                    ]
                    found = False
                    for alt_path in alternative_paths:
                        if os.path.exists(alt_path):
                            st.session_state['data'] = load_data(alt_path)
                            if 'processed_data' in st.session_state: 
                                del st.session_state['processed_data']
                            st.success(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {alt_path}")
                            st.rerun()
                            found = True
                            break
                    if not found:
                        st.error(f"âŒ æµ‹è¯•æ–‡ä»¶æœªæ‰¾åˆ°ã€‚è¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„ï¼š\n- {default_data_path}\n- {alternative_paths[0]}")
                        st.info("ğŸ’¡ æç¤ºï¼šæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸Šæ–¹çš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½ä¸Šä¼ CSVæ–‡ä»¶")
                      
        if 'data' in st.session_state:
            st.success(f"ğŸ“Š å·²åŠ è½½ {len(st.session_state['data'])} æ¡æ•°æ®")

    # ä¸»é€»è¾‘è·¯ç”±
    if 'data' in st.session_state:
        df = st.session_state['data'].copy()
        
        # ä»session_stateè·å–é¢„å¤„ç†è®¾ç½®
        if 'preprocessing_settings' not in st.session_state:
            # å¦‚æœè®¾ç½®ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            preprocessing_settings = {
                'missing_method': 'interpolation',
                'outlier_method': '3sigma',
                'do_log': False
            }
        else:
            preprocessing_settings = st.session_state['preprocessing_settings']
        
        missing_method = preprocessing_settings['missing_method']
        outlier_method = preprocessing_settings['outlier_method']
        do_log = preprocessing_settings['do_log']
        
        if 'processed_data' not in st.session_state:
            with st.spinner("æ­£åœ¨è¿›è¡Œæ™ºèƒ½æ¸…æ´—ä¸é¢„å¤„ç†..."):
                df_processed = preprocess_data(
                    df,
                    missing_method=missing_method,
                    outlier_method=outlier_method,
                    do_log=do_log
                )

                st.session_state['processed_data'] = df_processed
        else:
            df_processed = st.session_state['processed_data']
        
        # é¡µé¢è·³è½¬
        if selected == "æ•°æ®æ´å¯Ÿ":
            page_data_insight(df_processed)
        elif selected == "å½’å› åˆ†æ":
            page_attribution_analysis(df_processed)
        elif selected == "âš”ï¸ æ¨¡å‹ç«æŠ€åœº" or selected == "æ¨¡å‹ç«æŠ€åœº":
            page_model_arena(df_processed)
        elif selected == "ğŸ¯ åˆ†ç±»ä¸çŠ¶æ€" or selected == "åˆ†ç±»ä¸çŠ¶æ€":
            page_classification(df_processed)
        elif selected == "é¢„è­¦ä¸­å¿ƒ":
            page_warning_center(df_processed)
        elif selected == "ğŸ“‹ è¯„ä¼°ä¸­å¿ƒ" or selected == "è¯„ä¼°ä¸­å¿ƒ":
            page_evaluation_center(df_processed)
            
    else:
        # æ¬¢è¿é¡µï¼ˆç©ºçŠ¶æ€ï¼‰
        st.markdown("""
        <div style="display: flex; justify-content: center; align-items: center; height: 60vh; flex-direction: column;">
            <h2 style="color: #ccc;">ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ç³»ç»Ÿ</h2>
            <p style="color: #999;">è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ åŠ è½½æ•°æ®ä»¥å¼€å§‹åˆ†æ</p>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()